<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xi="http://www.w3.org/2001/XInclude" version="5.0" xml:lang="hu">
    <info>
        <title>Helló, !</title>
        <keywordset>
            <keyword/>
        </keywordset>
    </info>
    <section>
        <title>OOCWC Boost ASIO hálózatkezelése</title>
        <para>
		Mutassunk rá a scanf szerepére és használatára! https://github.com/nbatfai/robocaremulator/blob/master/justine/rcemu/src/carlexer.ll
        </para>
        <para>
            Megoldás videó:
        </para>
        <para>
            Megoldás forrása:                
        </para>
        <para>
            A scanf segítségével adatokat olvashatunk be az adott inputból, amit aztán eltárolunk későbbi használatra típus szerint.
            Vegyük például ezt a sort: 
        </para>
        <para>
<![CDATA[
std::sscanf(yytext, "<pos %d %u %u", &m_id, &from, &to);
]]>
</para>
        <para>
        A kapott inputból kiíratja a poziciót, amiket a m_id, from és a to referenciaértékekből kapott meg. Ezekből az id signed decimális, a másik kettő pedig unsigned (tehát negatív is lehet), decimális értékben tér vissza.
        </para>
        <para>Egy másik példában is hasonlóképp működik a dolog, viszont itt bejönnek más értékek is:</para>
        <para>
        <![CDATA[
while ( std::sscanf ( data+nn, "<OK %d %u %u %u>%n", &idd, &f, &t, &s, &n ) == 4 )
{
    nn += n;
    gangsters.push_back ( Gangster {idd, f, t, s} );
}
]]>
</para>
<para>Itt ugyanaz van, mint az elősben annyi különbséggel, hogy bejött egy n érték is. Ez az érték azt mutatja, hány paramétert olvasunk be. Amíg ez a szám 4-el egyenlő, addig megy a while ciklus és addig rakosgatjuk a gangsters vektor végébe az értékeket. A data+nn annyit tesz
mindössze, hogy a soron következő gangster-t megkapjuk, el kell tolnunk annyival a paramétereket, amennyi az nn változóban van. Az nn változó mindig 4-el nő, amíg a feltétel igaz.</para>
    </section> 
	    <section>
        <title>SamuCam</title>
        <para>
		Mutassunk rá a webcam (pl. Androidos mobilod) kezelésére ebben a projektben:
https://github.com/nbatfai/SamuCam
        </para>
        <para>
            Megoldás videó:
        </para>
        <para>
            Megoldás forrása:                
        </para>
        <para>
            A program futtatásához szükségünk van a Qt és az OpenCV könyvtárakra. Ezeket beszerezve, Linux alatt a kapott utasításokat követve
            futtathatjuk a programot.
        </para>
        <para>Először le kell klónoznunk a github repót a git clone https://github.com/nbatfai/SamuCam.git segítségével. Ez után le kell szednünk az opencv-hez szükséges
        frontalface xml fájlt, amit a wget https://github.com/Itseez/opencv/raw/master/data/lbpcascades/lbpcascade_frontalface.xml parancs kiadásával megtehetünk. Aztán checkoutolnunk kell a vInitialHack-et, és qmakelnünk kell
        a SamuLife.pro fájlt, ami a Qt/5.5/gcc_64/bin mappán belül van. Ha a qmake sikerült, le kell makelnünk az így kapott fájlokat. Ez után készen vagyunk a program fordításával. 
        Nincs más dolgunk, mint futtatni a ./SamuCamp paranccsal. Ha IP kamerát szeretnénk hozzáadni, mint bemeneti eszköz, az az --ip kapcsolóval és a kamera linkjével megtehetjük. Amennyiben nincs megosztva az interneten, úgy a lokális
        ip-t használva el tudjuk érni.</para>
        <para>Ha mégsem sikerülne (ahogy nekem sem sikerült, mivel nincs grafikus felületű linuxom), akkor sincs baj, mivel a feladatunk nem ez volt. Be kell mutatnunk, hogyan kezeli a program a webkamerákat. 
        Ezt meglepő módon a SamuCam.cpp-ben találjuk, azon belül is a videostreamnél rögtön az elején, amit az OpenCV biztosít számunkra.</para>
                <programlisting language='c++'><![CDATA[
SamuCam::SamuCam ( std::string videoStream, int width = 176, int height = 144 )
  : videoStream ( videoStream ), width ( width ), height ( height )
{
  openVideoStream();
}

SamuCam::~SamuCam ()
{
}

void SamuCam::openVideoStream()
{
  videoCapture.open ( videoStream );

  videoCapture.set ( CV_CAP_PROP_FRAME_WIDTH, width );
  videoCapture.set ( CV_CAP_PROP_FRAME_HEIGHT, height );
  videoCapture.set ( CV_CAP_PROP_FPS, 10 );
}
]]></programlisting>
<para>Bemeneti értékként deklaráljuk a szélességet és a magasságot, majd beállítjuk a streamet ennek megfelelően, és rakunk rá egy 10 fps-es korlátot, a minél alacsonyabb forráshasználat reményében. Ezzel meg is van a bemenetünk, amire ráengedjük az arcfelismerést.</para>
<programlisting language='c++'><![CDATA[
void SamuCam::run()
{

  cv::CascadeClassifier faceClassifier;

  std::string faceXML = "lbpcascade_frontalface.xml"; // https://github.com/Itseez/opencv/tree/master/data/lbpcascades

  if ( !faceClassifier.load ( faceXML ) )
    {
      qDebug() << "error: cannot found" << faceXML.c_str();
      return;
    }

  cv::Mat frame;

  while ( videoCapture.isOpened() )
    {

      QThread::msleep ( 50 );
      while ( videoCapture.read ( frame ) )
        {

          if ( !frame.empty() )
            {

              cv::resize ( frame, frame, cv::Size ( 176, 144 ), 0, 0, cv::INTER_CUBIC );

              std::vector<cv::Rect> faces;
              cv::Mat grayFrame;

              cv::cvtColor ( frame, grayFrame, cv::COLOR_BGR2GRAY );
              cv::equalizeHist ( grayFrame, grayFrame );

              faceClassifier.detectMultiScale ( grayFrame, faces, 1.1, 4, 0, cv::Size ( 60, 60 ) );

              if ( faces.size() > 0 )
                {

                  cv::Mat onlyFace = frame ( faces[0] ).clone();

                  QImage* face = new QImage ( onlyFace.data,
                                              onlyFace.cols,
                                              onlyFace.rows,
                                              onlyFace.step,
                                              QImage::Format_RGB888 );

                  cv::Point x ( faces[0].x-1, faces[0].y-1 );
                  cv::Point y ( faces[0].x + faces[0].width+2, faces[0].y + faces[0].height+2 );
                  cv::rectangle ( frame, x, y, cv::Scalar ( 240, 230, 200 ) );


                  emit  faceChanged ( face );
                }

              QImage*  webcam = new QImage ( frame.data,
                                             frame.cols,
                                             frame.rows,
                                             frame.step,
                                             QImage::Format_RGB888 );

              emit  webcamChanged ( webcam );

            }

          QThread::msleep ( 80 );

        }

      if ( ! videoCapture.isOpened() )
        {
          openVideoStream();
        }

    }

}
]]></programlisting>
<para>Az imént letöltött xml-ünk hála képesek vagyunk megkérni az OpenCV-t arra, hogy emberi arcokat ismerjen fel. Kezeljük a kivételeket, mielőtt elkezdjük a műveletet, így amíg nincs bemeneti stream (tehát a webcamerát nem "csaltuk" be a programba) vagy netán
hiányzik az arcfelismerő xml, a programunk nem fog elindulni. Ha ezzel megvagyunk, a másodpercenkénti 10 képet feldolgozzuk mindaddig, amíg a stream meg nem szakad. Ehhez a kapott, színes képet szürkébe konvertáljuk, így könnyebb a gépnek dolgoznia vele. A különböző framekből
kivágjuk a potenciális arcot, és berakjuk egy új képbe. Ezt minden képkockán elvégezzük, így ha kimegyünk a képből vagy mozgunk, akkor is tudni fogja, hogy merre van az arcunk.</para>
    </section> 
	    <section>
        <title>BrainB</title>
        <para>
		Mutassuk be a Qt slot-signal mechanizmust ebben a projektben: https://github.com/nbatfai/esporttalent-search
        </para>
        <para>
            Megoldás videó:
        </para>
        <para>
            Megoldás forrása:                
        </para>
        <para>
            Ehhez a programozh is szükségünk van a Qt és az OpenCV könyvtárakra. A git repó klónozása után qmake-el lemakeljük a BrainB.pro fájlt. Ez után a programot megnyitva, egy olyan "játékot" kapunk, amiben a Samu nevű entityt kell követnünk az egérrel,
            közben pedig újak jönnek be a képbe. 
        </para>
        <para>A feladatban a slot-signal mechanizmust kell bemutatnunk, ami egy olyan folyamat, amely lehetőséget biztosít különböző eventek összekapcsolására, így átláthatóbbá és könnyebben kezelhetővé téve a program háttérbeli feldolgozását.</para>
        <para>A BrainBWin.cpp fájlban a BrainBWin funkcióban használjuk a mechanizmust.</para>
                        <programlisting language='c++'><![CDATA[
        BrainBWin::BrainBWin ( int w, int h, QWidget *parent ) : QMainWindow ( parent )
{
        statDir = appName + " " + appVersion + " - " + QDate::currentDate().toString() + QString::number ( QDateTime::currentMSecsSinceEpoch() );

        brainBThread = new BrainBThread ( w, h - yshift );
        brainBThread->start();

        connect ( brainBThread, SIGNAL ( heroesChanged ( QImage, int, int ) ),
                  this, SLOT ( updateHeroes ( QImage, int, int ) ) );

        connect ( brainBThread, SIGNAL ( endAndStats ( int ) ),
                  this, SLOT ( endAndStats ( int ) ) );

}
]]></programlisting>
    <para>Ez azt jelenti, hogyha meghívjuk például a heroesChanged függvényt, akkor helyette az updateHeroes hívódjon meg.</para>
    </section> 
        
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        
</chapter>                
